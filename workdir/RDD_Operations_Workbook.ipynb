{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOLmy1fvIMtzPy3haWByzwY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Prerequisites"],"metadata":{"id":"v2LNh0kIQT9X"}},{"cell_type":"markdown","source":["**Installing and Configuring PySpark**"],"metadata":{"id":"RoowY3S_5PtG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"kDd0yycW48-U"},"outputs":[],"source":["#install Apache Spark 3.0.1 with Hadoop 2.7 from here.\n","!wget https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop2.7.tgz\n","\n","# Now, we just need to unzip that folder.\n","!tar -xvzf spark-3.0.0-bin-hadoop2.7.tgz\n","!pip install findspark\n","\n","\n","import os\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop2.7\"\n","import findspark\n","findspark.init()\n"]},{"cell_type":"markdown","source":["**Download Dataset**"],"metadata":{"id":"tW9bM6z-50u9"}},{"cell_type":"code","source":["!wget --continue https://raw.githubusercontent.com/naveenpn-trainer/big-data-developer-course/main/workdir/Transactions.txt -O Transactions.txt"],"metadata":{"id":"fgi_Wgze53lu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Introduction to RDD's"],"metadata":{"id":"DaN_v1WF5ZvF"}},{"cell_type":"markdown","source":["# RDD Operations"],"metadata":{"id":"7_ZKlS-o5lrE"}},{"cell_type":"markdown","source":["## Transformations"],"metadata":{"id":"Kcdgy0qc5btM"}},{"cell_type":"code","source":[],"metadata":{"id":"xLn0-8bl5bEr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Actions"],"metadata":{"id":"biBUeuJk5dWI"}},{"cell_type":"code","source":[],"metadata":{"id":"Vri5pFGM5eFc"},"execution_count":null,"outputs":[]}]}
